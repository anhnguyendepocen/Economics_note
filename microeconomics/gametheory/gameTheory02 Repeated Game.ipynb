{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Repeated Games"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finitely Repeated Games\n",
    "\n",
    "## Definition of a repeated game\n",
    "\n",
    "A repeated game is played over discrete time periods. Each time period is index by $0<t≤T$ where $T$ is the total number of periods.\n",
    "\n",
    "In each period $N$ players play a static game referred to as the **stage game** independently and simultaneously selecting actions.\n",
    "\n",
    "Players make decisions in **full knowledge of the history of the game** played so far (ie the actions chosen by each player in each previous time period).\n",
    "\n",
    "The payoff is defined as the **sum of the utilities** in each stage game for every time period.\n",
    "\n",
    "### Definition of a strategy in a repeated game\n",
    "\n",
    "A repeated game strategy must specify the **action** of a player in a given stage game given the **entire history** of the repeated game.\n",
    "\n",
    "for example: \"always play r1\"\n",
    "\n",
    "\"play r2 until opponent plays c1, then play r1\"\n",
    "\n",
    "\n",
    "\n",
    "### Subgame perfect Nash equilibrium in repeated games\n",
    "\n",
    "Theorem of a sequence of stage Nash profiles\n",
    "\n",
    "For any repeated game, any sequence of stage Nash profiles gives the outcome of a subgame perfect Nash equilibrium\n",
    "\n",
    "\n",
    "\n",
    "ref:\n",
    "http://vknight.org/Year_3_game_theory_course/Content/Chapter_09_Finitely_Repeated_Games/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cooperation in the Infinitely Repeated Prisoner's Dilemma\n",
    "\n",
    "History dependent: players' moves are influenced by the history/ previous moves.\n",
    "\n",
    "Discount rate: r    $0<r<1$\n",
    "\n",
    "how much you value future  relatively to now.\n",
    "\n",
    "\n",
    "Grim Trigger strategy: Play r1 unless the other player played c2\n",
    "\n",
    "${C,D,G}$\n",
    "\n",
    "$$p_1(G) = high/(1+r) $$\n",
    "\n",
    "$$p_1(C) = superhigh + low*r/(1+r) $$\n",
    "\n",
    "If player value future,player willing to forgo short gain to earn long term gain. \n",
    "\n",
    "\n",
    " If one of the players is always confessing, regardless of what the other player is doing, then neither player has anything to gain by not confessing (i.e. there is no \"punishment\" for confessing). Therefore, \"Always Confess\" by both players is an equilibrium strategy.\n",
    "\n",
    "ref:\n",
    "https://www.youtube.com/watch?v=t2g0Jg-6LHw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Infinitely Repeated Games\n",
    "\n",
    "\n",
    "#### Discounting\n",
    "\n",
    "To illustrate infinitely repeated games $(T→∞)$ we will consider a Prisoners dilemma as our stage game.\n",
    "$$\n",
    "% <![CDATA[\n",
    "\\begin{pmatrix}\n",
    "(2,2)&(0,3)\\\\\n",
    "(3,0)&(1,1)\n",
    "\\end{pmatrix} %]]>\n",
    "$$\n",
    "\n",
    "- Let us denote $s_C$ as the strategy “cooperate at every stage”. \n",
    "\n",
    "- Let us denote $s_D$ as the strategy “defect at every stage”.\n",
    "\n",
    "If we assume that both players play $s_{C}$ their utility would be:\n",
    "\n",
    "$$U_1(s_{C},s_{C})=U_2(s_{C},s_{C})=\\sum_{t=1}^\\infty2>\\infty$$\n",
    "\n",
    "Similarly:\n",
    "\n",
    "$$U_1(s_{D},s_{D})=U_2(s_{D},s_{D})=\\sum_{t=1}^\\infty1>\\infty$$\n",
    "\n",
    "\n",
    "It is impossible to compare these two strategies. To be able to carry out analysis of strategies in infinitely repeated games we make use of a **discounting factor** $0<δ<1$.\n",
    "\n",
    "\n",
    "- The interpretation of $δ$ is that there is less importance given to future payoffs. \n",
    "\n",
    "- One way of thinking about this is that “the probability of recieveing the future payoffs decreases with time”.\n",
    "\n",
    "\n",
    "In this case we write the utility in an infinitely repeated game as:\n",
    "\n",
    "$$U_i(r,c)=\\sum_{t=1}^\\infty\\delta^{t-1}u_i(r(t),c(t))$$\n",
    "\n",
    "#### Conditions for cooperation in Prisoner’s Dilemmas\n",
    "\n",
    "Let us consider the **“Grudger”** strategy (which we denote $s_G$):\n",
    "\n",
    ">“Start by cooperating until your opponent defects at which point defect in all future stages.”\n",
    "\n",
    "If both players play $s_G$ we have $s_G=s_C$:\n",
    "\n",
    "$$U_1(s_{G},s_{G})=U_2(s_{G},s_{G})=2/(1-\\delta)$$\n",
    "\n",
    "\n",
    "If we assume that $S1=S2={sC,sD,sG}$ and player 2 deviates from $S_G$ at the first stage to $s_D$ we get:\n",
    "\n",
    "\n",
    "$$U_2(s_{G},s_{D})=3+\\sum_{t=2}^{\\infty}\\delta^{t-1} 1=3+\\delta/(1-\\delta)$$\n",
    "\n",
    "since \n",
    "$$\\sum_{t=1}^\\infty\\delta^{t-1}=1/(1-\\delta)$$\n",
    "\n",
    "Deviation from $s_G$ to $s_D$ is rational if and only if:\n",
    "\n",
    "$$% <![CDATA[\n",
    "2/(1-\\delta)<3+\\delta/(1-\\delta) %]]>$$\n",
    "\n",
    "$$% <![CDATA[\n",
    "\\delta< 1/2 %]]$$\n",
    "\n",
    "thus if $δ$ is large enough $(s_G,s_G)$ is a Nash equilibrium.\n",
    "\n",
    "\n",
    "\n",
    "ref:\n",
    "http://vknight.org/Year_3_game_theory_course/Content/Chapter_10_Infinetely_Repeated_Games/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Folk Theorem:\n",
    "\n",
    "\n",
    "### Definition of individually rational payoffs\n",
    "\n",
    "Individually rational payoffs are average payoffs that exceed the stage game Nash equilibrium payoffs for both players.\n",
    "\n",
    "As an example consider the plot corresponding to a repeated Prisoner’s Dilemma.\n",
    "\n",
    "![](http://vknight.org/Year_3_game_theory_course/Content/images/L10-img01.png)\n",
    "\n",
    "\n",
    "### Folk Theorem for infinitely repeated games\n",
    "\n",
    "Let $(u^∗_1,u^∗_2)$ be a pair of Nash equilibrium payoffs for a stage game. For every individually rational pair $(v_1,v_2)$ there exists $\\bar δ$ such that for all $1>δ>\\bar δ>0$ there is a subgame perfect Nash equilibrium with payoffs $(v_1,v_2)$.\n",
    "\n",
    "#### Proof\n",
    "\n",
    "Let $(σ^∗_1,σ^∗_2)$ be the stage Nash profile that yields $(u^∗_1,u^∗_2)$. Now assume that playing $\\bar σ_1∈ΔS_1$ and $\\bar σ_2∈ΔS_2$ in every stage gives $(v_1,v_2)$ (an individual rational payoff pair).\n",
    "\n",
    "Consider the following strategy:\n",
    "\n",
    ">“Begin by using $\\bar σ_i$ and continue to use $\\bar σ_i$ as long as both players use the agreed strategies. If any player deviates: use $σ^*_i$ for all future stages.”\n",
    "\n",
    "\n",
    "Recalling that player 1 would receive $v1$ in every stage with no devitation, the biggest gain to be made from deviating is if player 1 deviates in the first stage (all future gains are more heavily discounted). Thus if we can find $\\bar δ$ such that $δ>\\barδ$ implies that $U_1^{(1)}\\leq \\frac{v_1}{1-\\delta}$ then player 1 has no incentive to deviate.\n",
    "\n",
    "$$% <![CDATA[\n",
    "\\begin{aligned}\n",
    "U_1^{(1)}=u_1(\\sigma_1',\\bar\\sigma_2)+u_1^*\\frac{\\delta}{1-\\delta}&\\leq\\frac{v_1}{1-\\delta}\\\\\n",
    "(1-\\delta)u_1(\\sigma_1',\\bar\\sigma_2)+u_1^*\\delta&\\leq v_1\\\\\n",
    "u_1(\\sigma_1',\\bar\\sigma_2)-v_1&\\leq \\delta(u_1(\\sigma_1',\\bar\\sigma_2)-u_1^*)\\\\\n",
    "\\end{aligned} %]]>$$\n",
    "\n",
    "\n",
    "\n",
    "as $u_1(\\sigma_1’,\\bar \\sigma_2)>v_1>u_1^*$, taking $\\bar\\delta=\\frac{u_1(\\sigma_1’,\\bar\\sigma_2)-v_1}{u_1(\\sigma_1’,\\bar\\sigma_2)-u_1^*}$ gives the required required result for player 1 and repeating the argument for player 2 completes the proof of the fact that the prescribed strategy is a Nash equilibrium.\n",
    "\n",
    "ref:\n",
    "https://www.youtube.com/watch?v=2pORjDDRU_8\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-18T06:37:43.789989Z",
     "start_time": "2018-02-18T06:37:37.199560Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(C, C), (D, C), (C, D), (D, C), (C, D)]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#http://axelrod.readthedocs.io/en/latest/\n",
    "#Create matches between two players:\n",
    "#!pip install --user axelrod\n",
    "import axelrod as axl\n",
    "players = (axl.Alternator(), axl.TitForTat())\n",
    "match = axl.Match(players, 5)\n",
    "interactions = match.play()\n",
    "interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-18T06:37:44.708165Z",
     "start_time": "2018-02-18T06:37:43.792380Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Playing matches: 100%|██████████| 10/10 [00:00<00:00, 32.44it/s]\n",
      "Analysing: 100%|██████████| 25/25 [00:00<00:00, 42.42it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Grudger', 'Tit For Tat', 'Cooperator', 'Alternator']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Build full tournaments between groups of players:\n",
    "import axelrod as axl\n",
    "players = (axl.Cooperator(), axl.Alternator(), axl.TitForTat(), axl.Grudger())\n",
    "tournament = axl.Tournament(players)\n",
    "results = tournament.play()\n",
    "results.ranked_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-18T06:37:45.123879Z",
     "start_time": "2018-02-18T06:37:44.712002Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jon/anaconda3/lib/python3.6/site-packages/matplotlib/figure.py:403: UserWarning: matplotlib is currently using a non-GUI backend, so cannot show the figure\n",
      "  \"matplotlib is currently using a non-GUI backend, \"\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1gAAAGoCAYAAABbkkSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBhFYAAAAg/x/F4+agKUcdX4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc3a229a828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "plot = axl.Plot(results)\n",
    "p = plot.boxplot()\n",
    "p.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dynamic Games\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extensive form games and backwards induction\n",
    "\n",
    "\n",
    "### Definition of an Information set\n",
    "\n",
    "Two nodes of a game tree are said to be part of the same information set if the player at that node cannot differentiate between them.\n",
    "\n",
    "\n",
    "### Backwards induction\n",
    "\n",
    "To analyse such games we assume that players not only attempt to optimize their overall utility but optimize their utility conditional on any information set.\n",
    "\n",
    "#### Definition of sequential rationality\n",
    "\n",
    "Sequential rationality: An optimal strategy for a player should maximise that player’s expected payoff, conditional on every information set at which that player has a decision.\n",
    "\n",
    "With this notion in mind we can now define an analysis technique for extensive form games:\n",
    "\n",
    "### Definition of backward induction\n",
    "\n",
    "Backward induction: This is the process of analysing a game from back to front. At each information set we remove strategies that are dominated.\n",
    "\n",
    "\n",
    "### Theorem of existence of Nash equilibrium in games of perfect information.\n",
    "\n",
    "Every finite game with perfect information has a Nash equilibrium in pure strategies. Backward induction identifies an equilibrium.\n",
    "\n",
    "#### Proof\n",
    "\n",
    "Recalling the properties of sequential rationality we see that no player will have an incentive to deviate from the strategy profile found through backward induction. Secondly every finite game with perfect information can be solved using backward inductions which gives the result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Sub-Game Perfect Equilibria \n",
    "\n",
    "\n",
    "\n",
    "### Definition of a subgame\n",
    "\n",
    "In an extensive form game, a node $x$ is said to initiate a subgame if and only if $x$ and all successors of $x$ are in information sets containing only successors of $x$.\n",
    "\n",
    "A game that **does not have perfect information nodes**\n",
    "\n",
    "- c, f and b initiate subgames \n",
    "\n",
    "- but all of b’s successors: d and e do not \n",
    "\n",
    "![](http://vknight.org/Year_3_game_theory_course/Content/images/L08-img02.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition of subgame perfect equilibrium\n",
    "\n",
    "A subgame perfect Nash equilibrium is a Nash equilibrium in which the strategy profiles specify Nash equilibria for every subgame of the game.\n",
    "\n",
    "Note that this includes subgames that might not be reached during play!\n",
    "\n",
    "- subgame perfect Nash equilibrium is a refinement of Nash equilibrium.\n",
    "- In games with perfect information, the Nash equilibrium obtained through backwards induction is subgame perfect.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One example\n",
    "\n",
    "![](https://www.complexityexplorer.org/ckeditor_assets/pictures/698/content_q2.png)\n",
    "\n",
    "\n",
    "- First, figure out what player 2 would play for each of player 1's possible actions. \n",
    "\n",
    "- Then, pick the strategy for player 1 that gives the highest payout conditional on player 2 best responding to whatever player 1 chooses.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stackelberg game\n",
    "\n",
    "Let us consider the Cournot duopoly game. Recall:\n",
    "\n",
    "> Suppose that two firms 1 and 2 produce an identical good (ie consumers do not care who makes the good). The firms decide at the same time to produce a certain quantity of goods: $q1,q2≥0$. All of the good is sold but the price depends on the number of goods:\n",
    "\n",
    "$$p=K−q1−q2$$\n",
    "\n",
    "We also assume that the firms both pay a production cost of $k$ per bricks.\n",
    "\n",
    "However we will modify this to assume that there is **a leader and a follower**, ie the **firms do not decide at the same time**. This game is called a **Stackelberg leader follower game**.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Let us represent this as a normal form game.\n",
    "\n",
    "\n",
    "![](http://vknight.org/Year_3_game_theory_course/Content/images/L07-img13.png)\n",
    "\n",
    "We use backward induction to identify the Nash equilibria. The dominant strategy for the follower is:\n",
    "\n",
    "$$q_2^*(q_1)=\\frac{K-k-q_1}{2}$$\n",
    "\n",
    "The game thus reduces as shown.\n",
    "\n",
    "\n",
    "![](http://vknight.org/Year_3_game_theory_course/Content/images/L07-img14.png)\n",
    "\n",
    "The leader thus needs to maximise:\n",
    "\n",
    "\n",
    "$$u_1(q_1)=(K-q_1-\\frac{K-k-q_1}{2})q_1-kq_1=(\\frac{K-q_1+k}{2})q_1-kq_1$$\n",
    "\n",
    "\n",
    "Differentiating and equating to 0 gives:\n",
    "\n",
    "$q_1^*=\\frac{K-k}{2}$  which in turn gives: $q_2^*=\\frac{K-k}{4}$\n",
    "\n",
    "\n",
    "The total amount of goods produced is $\\frac{3(K-k)}{4}$ whereas in the Cournot game the total amount of good produced was $\\frac{2(K-k)}{3}$. Thus **more goods are produced in the Stackelberg game**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ref:\n",
    "    \n",
    "http://vknight.org/Year_3_game_theory_course/Content/Chapter_01-Introduction/\n",
    "\n",
    "Gambit http://www.gambit-project.org\n",
    "https://github.com/gambitproject/gambit\n",
    "\n",
    "\n",
    "A research tool for the Iterated Prisoner's Dilemma http://axelrod.readthedocs.org/\n",
    "\n",
    "https://github.com/Axelrod-Python/Axelrod\n",
    "\n",
    "http://axelrod.readthedocs.io/en/stable/tutorials/getting_started/installation.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!pip install --user axelrod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!pip install --user gambit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import gambit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://gte.csc.liv.ac.uk/gte/builder/\n",
    "\n",
    "An extensive or strategic-form game can be created and nicely displayed with a graphical user interface in a web browser. State-of-the-art algorithms then compute one or all Nash equilibria of the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
