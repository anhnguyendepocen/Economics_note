{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests for Heteroscedasticity\n",
    "\n",
    "Under heteroscedastic errors, it is well known that OLS estimators are unbiased and consistent, but inefficient and provide incorrect standard errors. \n",
    "\n",
    "Hence it is very important to detect this anomaly in your regression.\n",
    "\n",
    "\n",
    "We will illustrate how to test for heteroscedasticity using Current Population Survey (CPS) data consisting on 100 observations on wages, educational level, years of experience, and unionization status of U.S. male workers. The data was borrowed from J&DN’s (1997) Econometric Methods, and slightly adjusted for the purposes of this tutorial. The variables are defined as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-02T01:36:29.142253Z",
     "start_time": "2018-03-02T01:36:28.731Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>lnwage</th><th scope=col>grade</th><th scope=col>exp</th><th scope=col>union</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>2.331172</td><td> 8      </td><td>22      </td><td>0       </td></tr>\n",
       "\t<tr><td>1.504077</td><td>14      </td><td> 2      </td><td>0       </td></tr>\n",
       "\t<tr><td>3.911523</td><td>16      </td><td>22      </td><td>0       </td></tr>\n",
       "\t<tr><td>2.197225</td><td> 8      </td><td>34      </td><td>1       </td></tr>\n",
       "\t<tr><td>2.788093</td><td> 9      </td><td>47      </td><td>0       </td></tr>\n",
       "\t<tr><td>2.351375</td><td> 9      </td><td>32      </td><td>0       </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llll}\n",
       " lnwage & grade & exp & union\\\\\n",
       "\\hline\n",
       "\t 2.331172 &  8       & 22       & 0       \\\\\n",
       "\t 1.504077 & 14       &  2       & 0       \\\\\n",
       "\t 3.911523 & 16       & 22       & 0       \\\\\n",
       "\t 2.197225 &  8       & 34       & 1       \\\\\n",
       "\t 2.788093 &  9       & 47       & 0       \\\\\n",
       "\t 2.351375 &  9       & 32       & 0       \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "lnwage | grade | exp | union | \n",
       "|---|---|---|---|---|---|\n",
       "| 2.331172 |  8       | 22       | 0        | \n",
       "| 1.504077 | 14       |  2       | 0        | \n",
       "| 3.911523 | 16       | 22       | 0        | \n",
       "| 2.197225 |  8       | 34       | 1        | \n",
       "| 2.788093 |  9       | 47       | 0        | \n",
       "| 2.351375 |  9       | 32       | 0        | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  lnwage   grade exp union\n",
       "1 2.331172  8    22  0    \n",
       "2 1.504077 14     2  0    \n",
       "3 3.911523 16    22  0    \n",
       "4 2.197225  8    34  1    \n",
       "5 2.788093  9    47  0    \n",
       "6 2.351375  9    32  0    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d.d<-read.table(\"http://www.econ.uiuc.edu/~econ508/data/CPS.txt\",header=T)\n",
    "head(d.d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-02T01:55:47.376156Z",
     "start_time": "2018-03-02T01:55:47.319Z"
    }
   },
   "outputs": [],
   "source": [
    "lnwage<-d.d$lnwage\n",
    "grade<-d.d$grade\n",
    "exp<-d.d$exp\n",
    "union<-d.d$union\n",
    "exp2<-exp^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-02T01:56:06.542325Z",
     "start_time": "2018-03-02T01:56:06.507Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = lnwage ~ grade + exp + exp2 + union)\n",
       "\n",
       "Residuals:\n",
       "     Min       1Q   Median       3Q      Max \n",
       "-1.01553 -0.28642 -0.04438  0.29378  1.45359 \n",
       "\n",
       "Coefficients:\n",
       "              Estimate Std. Error t value Pr(>|t|)    \n",
       "(Intercept)  0.5951062  0.2834855   2.099 0.038447 *  \n",
       "grade        0.0835426  0.0200928   4.158 7.04e-05 ***\n",
       "exp          0.0502742  0.0141370   3.556 0.000589 ***\n",
       "exp2        -0.0005617  0.0002879  -1.951 0.053954 .  \n",
       "union        0.1659285  0.1244544   1.333 0.185639    \n",
       "---\n",
       "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
       "\n",
       "Residual standard error: 0.47 on 95 degrees of freedom\n",
       "Multiple R-squared:  0.3718,\tAdjusted R-squared:  0.3453 \n",
       "F-statistic: 14.06 on 4 and 95 DF,  p-value: 4.794e-09\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary(lm(lnwage~grade+exp+exp2+union))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 1: White\n",
    "\n",
    "Run the OLS regression (as you’ve done above, the results are omitted):\n",
    "\n",
    "Get the residuals:\n",
    "\n",
    "Generate the squared residuals:\n",
    "\n",
    "Generate new explanatory variables, in the form of the squares of the explanatory variables and the cross-product of the explanatory variables:\n",
    "\n",
    "Because union is a dummy variable, its squared values are equal to the original values, and we don’t need to add the squared dummy in the model. Also the squared experience was already in the original model (in the form of exp2), so we don’t need to add that in this auxiliary regression.\n",
    "\n",
    "Regress the squared residuals into a constant, the original explanatory variables, and the set of auxiliary explanatory variables (squares and cross-products) you’ve just created:\n",
    "\n",
    "\n",
    "Get the sample size (N) and the R-squared (R2), and construct the test statistic N*R2:\n",
    "\n",
    "\n",
    "Under the null hypothesis, the errors are homoscedastic, and NR2 is asymptotically distributed as a Chi-squared with k-1 degrees of freedom (where k is the number of coefficients on the auxiliary regression). In this last case, k=13.\n",
    "And we observe that the test statistic NR2 is about 10.7881, while the Chi-squared(12, 5%) is about 21, much bigger than the test statistic. Hence, the null hypothesis (homoscedasticity) can not be rejected.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-02T02:01:36.332939Z",
     "start_time": "2018-03-02T02:01:36.245Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "10.788134523585"
      ],
      "text/latex": [
       "10.788134523585"
      ],
      "text/markdown": [
       "10.788134523585"
      ],
      "text/plain": [
       "[1] 10.78813"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "g<-lm(lnwage~grade+exp+exp2+union)\n",
    "\n",
    "g.resid<-g$resid\n",
    "\n",
    "g.resid2<-g.resid^2\n",
    "\n",
    "grade2<-grade^2 \n",
    "exp4<-exp2^2 \n",
    "gradexp<-grade*exp \n",
    "gradexp2<-grade*exp2 \n",
    "gradeuni<-grade*union \n",
    "exp3<-exp*exp2 \n",
    "expunion<-exp*union \n",
    "exp2uni<-exp2*union\n",
    "\n",
    "g.final<-lm(g.resid2~grade+exp+exp2+union+grade2+exp4+exp3+gradexp +gradexp2+gradeuni+expunion+exp2uni)\n",
    "\n",
    "N<-(g$df)+length(g$coef)\n",
    "R2<-summary(g.final)$r.squared \n",
    "N*R2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-02T02:12:08.318140Z",
     "start_time": "2018-03-02T02:12:08.280Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "21.0260698174831"
      ],
      "text/latex": [
       "21.0260698174831"
      ],
      "text/markdown": [
       "21.0260698174831"
      ],
      "text/plain": [
       "[1] 21.02607"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "qchisq(.95, df=12) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 2: Breusch-Pagan-Godfrey\n",
    "\n",
    "The Lagrange Multiplier test proposed by BPG can be executed as follows:\n",
    "\n",
    "Run the OLS regression (as you’ve done above, the output is omitted):\n",
    "\n",
    "    g<-lm(lnwage~grade+exp+exp2+union)\n",
    "    \n",
    "Get the sum of the squared residuals:\n",
    "\n",
    "\n",
    "    g.resid<-g$resid\n",
    "    g.ssr<-sum((g$resid)^2)\n",
    "    g.ssr \n",
    "    \n",
    "\n",
    "Generate a disturbance correction factor in the form of sum of the squared residuals divided by the sample size:\n",
    "\n",
    "    dcf<-g.ssr/((g$df)+length(g$coef))\n",
    "    \n",
    "Regress the adjusted squared errors (in the form of original squared errors divided by the correction factor) on a list of explanatory variables supposed to influence the heteroscedasticity. Following JDN, we will assume that, from the original dataset, only the main variables grade, exp, and union affect the heteroscedasticity. Hence:\n",
    "\n",
    "    adjerr2<-(g.resid^2)/dcf    \n",
    "    g.bptest<-lm(adjerr2~grade+exp+union)\n",
    "    summary(g.bptest)\n",
    "    \n",
    "    \n",
    "This auxiliary regression gives you a model sum of squares (ESS):\n",
    "\n",
    "    ess<-sum((g.bptest$fitted-mean(adjerr2))^2)  \n",
    "    \n",
    "    \n",
    "Under the null hypothesis of homoscedasticity, (1/2) ESS asymptotically converges to a Chi-squared(k-1, 5%), where k is the number of coefficients on the auxiliary regression. In the last case, k=4. Hence, we need to compare (1/2) ESS with a Chi-squared with 3 degrees of freedom and 5%. Doing so we get (1/2) ESS = 5.35, while the critical value of a Chi-squared (3, 5%) = 7.81. Therefore, the test statistic falls short of the critical value, and the null hypothesis of homoscedasticity can not be rejected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-02T02:33:46.973386Z",
     "start_time": "2018-03-02T02:33:46.896Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "20.9893846743636"
      ],
      "text/latex": [
       "20.9893846743636"
      ],
      "text/markdown": [
       "20.9893846743636"
      ],
      "text/plain": [
       "[1] 20.98938"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = adjerr2 ~ grade + exp + union)\n",
       "\n",
       "Residuals:\n",
       "    Min      1Q  Median      3Q     Max \n",
       "-1.5484 -0.8613 -0.4512  0.2889  8.7774 \n",
       "\n",
       "Coefficients:\n",
       "             Estimate Std. Error t value Pr(>|t|)\n",
       "(Intercept) -0.326100   0.949202  -0.344    0.732\n",
       "grade        0.098944   0.064351   1.538    0.127\n",
       "exp          0.009954   0.013198   0.754    0.453\n",
       "union       -0.582429   0.396332  -1.470    0.145\n",
       "\n",
       "Residual standard error: 1.579 on 96 degrees of freedom\n",
       "Multiple R-squared:  0.0428,\tAdjusted R-squared:  0.01288 \n",
       "F-statistic: 1.431 on 3 and 96 DF,  p-value: 0.2386\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "g<-lm(lnwage~grade+exp+exp2+union)\n",
    "g.resid<-g$resid\n",
    "g.ssr<-sum((g$resid)^2)\n",
    "g.ssr \n",
    "dcf<-g.ssr/((g$df)+length(g$coef))\n",
    "adjerr2<-(g.resid^2)/dcf    \n",
    "g.bptest<-lm(adjerr2~grade+exp+union)\n",
    "summary(g.bptest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-02T02:36:32.395436Z",
     "start_time": "2018-03-02T02:36:32.367Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "5.35238652372552"
      ],
      "text/latex": [
       "5.35238652372552"
      ],
      "text/markdown": [
       "5.35238652372552"
      ],
      "text/plain": [
       "[1] 5.352387"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ess<-sum((g.bptest$fitted-mean(adjerr2))^2)  \n",
    "1/2*ess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-02T02:36:40.493808Z",
     "start_time": "2018-03-02T02:36:40.472Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "7.81472790325118"
      ],
      "text/latex": [
       "7.81472790325118"
      ],
      "text/markdown": [
       "7.81472790325118"
      ],
      "text/plain": [
       "[1] 7.814728"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "qchisq(.95, df=3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-02T02:43:17.647329Z",
     "start_time": "2018-03-02T02:43:17.622Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 3: Goldfeld-Quandt\n",
    "\n",
    "Suppose now you believe a single explanatory variable is responsible for most of the heteroscedasticy in your model. For example, let’s say that experience (exp) is the “trouble-maker” variable. Hence, you can proceed with the Goldfeld-Quandt test as follows:\n",
    "\n",
    "Sort your data according to the variable exp. Then divide your data in, say, three parts, drop the observations of the central part, and run separate regressions for the bottom part (Regression 1) and the top part (Regression 2). After each regression, ask for the respective Residual Sum of Squares RSS:\n",
    "\n",
    "Then compute the ratio of the Residuals Sum of Squares, $R= RSS2/RSS1$. Under the null hypothesis of homoscedasticity, this ratio R is distributed according to a $F((n−c−2k)2,(n−c−2k)2)$, where $n$ is the sample size, c is the number of dropped observations, and k is the number of regressors in the model.\n",
    "\n",
    "To check your results you should get: $R<F$, and as a consequence can not reject the null hypothesis of homocedasticity\n",
    "\n",
    "### A simpler Approach\n",
    "\n",
    "The three Heteroscedasticity tests here presented are clasicals ones and so they are very likely to be packages that already calculate this for you. One of such packages is `lmtest` package. For example you could do the `Breusch-Pagan-Godfrey test` by typing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-02T02:58:57.399542Z",
     "start_time": "2018-03-02T02:58:57.219Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: lmtest\n",
      "Warning message:\n",
      "\"package 'lmtest' was built under R version 3.4.3\"Loading required package: zoo\n",
      "Warning message:\n",
      "\"package 'zoo' was built under R version 3.4.3\"\n",
      "Attaching package: 'zoo'\n",
      "\n",
      "The following objects are masked from 'package:base':\n",
      "\n",
      "    as.Date, as.Date.numeric\n",
      "\n"
     ]
    }
   ],
   "source": [
    " require(lmtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-02T02:59:08.349825Z",
     "start_time": "2018-03-02T02:59:08.321Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "\tBreusch-Pagan test\n",
       "\n",
       "data:  lnwage ~ grade + exp + exp2 + union\n",
       "BP = 6.1161, df = 4, p-value = 0.1906\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bptest(lnwage~grade+exp+exp2+union, studentize=FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also run a Goldfeld-Quandt test and check wether your results following the above steps coincide with the output of the gqtest included in the package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-02T03:01:23.469069Z",
     "start_time": "2018-03-02T03:01:23.442Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "\tGoldfeld-Quandt test\n",
       "\n",
       "data:  lnwage ~ grade + exp + exp2 + union\n",
       "GQ = 1.4923, df1 = 45, df2 = 45, p-value = 0.09161\n",
       "alternative hypothesis: variance increases from segment 1 to 2\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gqtest(lnwage~grade+exp+exp2+union)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
