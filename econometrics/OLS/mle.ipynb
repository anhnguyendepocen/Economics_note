{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook created: 2018-02-15 22:32:57  \n",
    "Generated from: _build_py/py/mle.rst  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import exp\n",
    "from scipy.misc import factorial\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "poisson_pmf = lambda y, mu: mu**y / factorial(y) * exp(-mu)\n",
    "y_values = range(0, 25)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "for mu in [1, 5, 10]:\n",
    "    distribution = []\n",
    "    for y_i in y_values:\n",
    "        distribution.append(poisson_pmf(y_i, mu))\n",
    "    ax.plot(y_values,\n",
    "            distribution,\n",
    "            label=('$\\mu$=' + str(mu)),\n",
    "            alpha=0.5,\n",
    "            marker='o',\n",
    "            markersize=8)\n",
    "\n",
    "ax.grid()\n",
    "ax.set_xlabel('$y$', fontsize=14)\n",
    "ax.set_ylabel('$f(y \\mid \\mu)$', fontsize=14)\n",
    "ax.axis(xmin=0, ymin=0)\n",
    "ax.legend(fontsize=14)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.max_columns = 10\n",
    "\n",
    "# Load in data and view\n",
    "df = pd.read_stata('https://github.com/QuantEcon/QuantEcon.lectures.code/raw/master/mle/fp.dta')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbil0_2008 = df[(df['year'] == 2008) & (\n",
    "    df['country'] != 'United States')].loc[:, 'numbil0']\n",
    "\n",
    "plt.subplots(figsize=(12, 8))\n",
    "plt.hist(numbil0_2008, bins=30)\n",
    "plt.xlim(xmin=0)\n",
    "plt.grid()\n",
    "plt.xlabel('Number of billionaires in 2008')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "y_values = range(0, 20)\n",
    "\n",
    "# Define a parameter vector with estimates\n",
    "beta = np.array([0.26, 0.18, 0.25, -0.1, -0.22]).T\n",
    "\n",
    "# Create some observations X\n",
    "datasets = [np.array([0, 1, 1, 1, 2]),\n",
    "            np.array([2, 3, 2, 4, 0]),\n",
    "            np.array([3, 4, 5, 3, 2]),\n",
    "            np.array([6, 5, 4, 4, 7])]\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "for X in datasets:\n",
    "    mu = exp(X @ beta)\n",
    "    distribution = []\n",
    "    for y_i in y_values:\n",
    "        distribution.append(poisson_pmf(y_i, mu))\n",
    "    ax.plot(y_values,\n",
    "            distribution,\n",
    "            label=('$\\mu_i$=' + str(round(mu, 1))),\n",
    "            marker='o',\n",
    "            markersize=8,\n",
    "            alpha=0.5)\n",
    "\n",
    "ax.grid()\n",
    "ax.legend()\n",
    "ax.set_xlabel('$y \\mid x_i$')\n",
    "ax.set_ylabel('$f(y \\mid x_i; \\\\beta )$')\n",
    "ax.axis(xmin=0, ymin=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "def plot_joint_poisson(mu=7, y_n=20):\n",
    "    yi_values = np.arange(0, y_n, 1)\n",
    "\n",
    "    # Create coordinate points of X and Y\n",
    "    X, Y = np.meshgrid(yi_values, yi_values)\n",
    "\n",
    "    # Multiply distributions together\n",
    "    Z = poisson_pmf(X, mu) * poisson_pmf(Y, mu)\n",
    "\n",
    "    fig = plt.figure(figsize=(12, 8))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.plot_surface(X, Y, Z.T, cmap='terrain', alpha=0.6)\n",
    "    ax.scatter(X, Y, Z.T, color='black', alpha=0.5, linewidths=1)\n",
    "    ax.set(xlabel='$y_1$', ylabel='$y_2$')\n",
    "    ax.set_zlabel('$f(y_1, y_2)$', labelpad=10)\n",
    "    plt.show()\n",
    "\n",
    "plot_joint_poisson(mu=7, y_n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = np.linspace(1, 20)\n",
    "logL = -(beta - 10) ** 2 - 10\n",
    "dlogL = -2 * beta + 20\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2, sharex=True, figsize=(12, 8))\n",
    "\n",
    "ax1.plot(beta, logL, lw=2)\n",
    "ax2.plot(beta, dlogL, lw=2)\n",
    "\n",
    "ax1.set_ylabel('$log \\mathcal{L(\\\\beta)}$',\n",
    "               rotation=0,\n",
    "               labelpad=35,\n",
    "               fontsize=15)\n",
    "ax2.set_ylabel(r'$\\frac{dlog \\mathcal{L(\\beta)}}{d \\beta}$ ',\n",
    "               rotation=0,\n",
    "               labelpad=35,\n",
    "               fontsize=19)\n",
    "ax2.set_xlabel('$\\\\beta$', fontsize=15)\n",
    "ax1.grid(), ax2.grid()\n",
    "plt.axhline(c='black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoissonRegression:\n",
    "\n",
    "    def __init__(self, y, X, beta):\n",
    "        self.X, self.y, self.beta = X, y, beta\n",
    "        self.n, self.k = X.shape\n",
    "\n",
    "    def mu(self):\n",
    "        return np.exp(np.dot(self.X, self.beta.T))\n",
    "\n",
    "    def logL(self):\n",
    "        y = self.y\n",
    "        mu = self.mu()\n",
    "        return np.sum(y*np.log(mu) - mu - np.log(factorial(y)))\n",
    "\n",
    "    def G(self):\n",
    "        mu = self.mu()\n",
    "        return np.dot(self.y - mu, self.X).reshape(self.k, 1)\n",
    "\n",
    "    def H(self):\n",
    "        X = self.X\n",
    "        mu = self.mu()\n",
    "        return -np.dot(mu * X.T, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def newton_raphson(model, tol=1e-3, max_iter=1000, display=True):\n",
    "\n",
    "    i = 0\n",
    "    error = 100  # Initial error value\n",
    "    format_string = \"{i:<13}{l:<16}{t:<30}\"\n",
    "\n",
    "    # Print header of output\n",
    "    if display:\n",
    "        header = format_string.format(i=\"Iteration_k\", l=\"Log-likelihood\", t=\"Theta\")\n",
    "        print(header)\n",
    "        print(\"-\" * len(header))\n",
    "\n",
    "    # While loop runs while any value in error is greater\n",
    "    # than the tolerance until max iterations are reached\n",
    "    while np.any(error > tol) and i < max_iter:\n",
    "        H, G = model.H(), model.G()\n",
    "        beta_new = model.beta - (np.linalg.inv(H) @ G).T\n",
    "        error = beta_new - model.beta\n",
    "        model.beta = beta_new.flatten()\n",
    "\n",
    "        # Print iterations\n",
    "        if display:\n",
    "            beta_list = ['%.4f' % t for t in list(np.round(model.beta, 3))]\n",
    "            update = format_string.format(i=i, l=round(model.logL(), 8), t=str(beta_list))\n",
    "            print(update)\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    print('Number of iterations: ' + str(i))\n",
    "    print('beta_hat = ' + str(model.beta))\n",
    "\n",
    "    return model.beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[1, 2, 5],\n",
    "              [1, 1, 3],\n",
    "              [1, 4, 2],\n",
    "              [1, 5, 2],\n",
    "              [1, 3, 1]])\n",
    "\n",
    "y = np.array([1, 0, 1, 1, 0])\n",
    "\n",
    "# Take a guess at initial betas\n",
    "init_beta = np.array([0.1, 0.1, 0.1])\n",
    "\n",
    "# Create an object with Poisson model values\n",
    "poi = PoissonRegression(y, X, beta=init_beta)\n",
    "\n",
    "# Use newton_raphson to find the MLE\n",
    "beta_hat = newton_raphson(poi, display=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```none\n",
    "Iteration_k  Log-likelihood  Theta\n",
    "-----------------------------------------------------------\n",
    "0            -4.34476224     ['-1.4890', '0.2650', '0.2440']\n",
    "1            -3.5742413      ['-3.3840', '0.5280', '0.4740']\n",
    "2            -3.39995256     ['-5.0640', '0.7820', '0.7020']\n",
    "3            -3.37886465     ['-5.9150', '0.9090', '0.8200']\n",
    "4            -3.3783559      ['-6.0740', '0.9330', '0.8430']\n",
    "5            -3.37835551     ['-6.0780', '0.9330', '0.8430']\n",
    "Number of iterations: 6\n",
    "beta_hat = [-6.07848205  0.93340226  0.84329625]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poi.G()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```none\n",
    "array([[ -3.95169226e-07],\n",
    "       [ -1.00114804e-06],\n",
    "       [ -7.73114556e-07]])\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logL = lambda x: -(x - 10) ** 2 - 10\n",
    "\n",
    "def find_tangent(beta, a=0.01):\n",
    "    y1 = logL(beta)\n",
    "    y2 = logL(beta+a)\n",
    "    x = np.array([[beta, 1], [beta+a, 1]])\n",
    "    m, c = np.linalg.lstsq(x, np.array([y1, y2]))[0]\n",
    "    return m, c\n",
    "\n",
    "beta = np.linspace(2, 18)\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "ax.plot(beta, logL(beta), lw=2, c='black')\n",
    "\n",
    "for beta in [7, 8.5, 9.5, 10]:\n",
    "    beta_line = np.linspace(beta-2, beta+2)\n",
    "    m, c = find_tangent(beta)\n",
    "    y = m*beta_line + c\n",
    "    ax.plot(beta_line, y, '-', c='purple', alpha=0.8)\n",
    "    ax.text(beta+2.05, y[-1], r'$G({}) = {:.0f}$'.format(beta, abs(m)), fontsize=12)\n",
    "    ax.vlines(beta, -24, logL(beta), linestyles='--', alpha=0.5)\n",
    "    ax.hlines(logL(beta), 6, beta, linestyles='--', alpha=0.5)\n",
    "\n",
    "ax.set(ylim=(-24, -4), xlim=(6, 13))\n",
    "ax.set_xlabel('$\\\\beta$', fontsize=15)\n",
    "ax.set_ylabel('$log \\mathcal{L(\\\\beta)}$',\n",
    "               rotation=0,\n",
    "               labelpad=25,\n",
    "               fontsize=15)\n",
    "ax.grid(alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.api import Poisson\n",
    "\n",
    "X = np.array([[1, 2, 5],\n",
    "              [1, 1, 3],\n",
    "              [1, 4, 2],\n",
    "              [1, 5, 2],\n",
    "              [1, 3, 1]])\n",
    "\n",
    "y = np.array([1, 0, 1, 1, 0])\n",
    "\n",
    "stats_poisson = Poisson(y, X).fit()\n",
    "print(stats_poisson.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```none\n",
    "Optimization terminated successfully.\n",
    "         Current function value: 0.675671\n",
    "         Iterations 7\n",
    "                          Poisson Regression Results\n",
    "==============================================================================\n",
    "Dep. Variable:                      y   No. Observations:                    5\n",
    "Model:                        Poisson   Df Residuals:                        2\n",
    "Method:                           MLE   Df Model:                            2\n",
    "Date:                Wed, 26 Jul 2017   Pseudo R-squ.:                  0.2546\n",
    "Time:                        15:41:38   Log-Likelihood:                -3.3784\n",
    "converged:                       True   LL-Null:                       -4.5325\n",
    "                                        LLR p-value:                    0.3153\n",
    "==============================================================================\n",
    "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
    "------------------------------------------------------------------------------\n",
    "const         -6.0785      5.279     -1.151      0.250     -16.425       4.268\n",
    "x1             0.9334      0.829      1.126      0.260      -0.691       2.558\n",
    "x2             0.8433      0.798      1.057      0.291      -0.720       2.407\n",
    "==============================================================================\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only year 2008\n",
    "df = df[df['year'] == 2008]\n",
    "\n",
    "# Add a constant\n",
    "df['const'] = 1\n",
    "\n",
    "# Variable sets\n",
    "reg1 = ['const', 'lngdppc', 'lnpop', 'gattwto08']\n",
    "reg2 = ['const', 'lngdppc', 'lnpop',\n",
    "        'gattwto08', 'lnmcap08', 'rintr', 'topint08']\n",
    "reg3 = ['const', 'lngdppc', 'lnpop', 'gattwto08', 'lnmcap08',\n",
    "        'rintr', 'topint08', 'nrrents', 'roflaw']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# Specify model\n",
    "poisson_reg = sm.Poisson(df[['numbil0']], df[reg1],\n",
    "                         missing='drop').fit(cov_type='HC0')\n",
    "print(poisson_reg.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```none\n",
    "Warning: Maximum number of iterations has been exceeded.\n",
    "         Current function value: 2.226090\n",
    "         Iterations: 35\n",
    "                          Poisson Regression Results\n",
    "==============================================================================\n",
    "Dep. Variable:                numbil0   No. Observations:                  197\n",
    "Model:                        Poisson   Df Residuals:                      193\n",
    "Method:                           MLE   Df Model:                            3\n",
    "Date:                Wed, 26 Jul 2017   Pseudo R-squ.:                  0.8574\n",
    "Time:                        15:41:38   Log-Likelihood:                -438.54\n",
    "converged:                      False   LL-Null:                       -3074.7\n",
    "                                        LLR p-value:                     0.000\n",
    "==============================================================================\n",
    "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
    "------------------------------------------------------------------------------\n",
    "const        -29.0495      2.578    -11.268      0.000     -34.103     -23.997\n",
    "lngdppc        1.0839      0.138      7.834      0.000       0.813       1.355\n",
    "lnpop          1.1714      0.097     12.024      0.000       0.980       1.362\n",
    "gattwto08      0.0060      0.007      0.868      0.386      -0.008       0.019\n",
    "==============================================================================\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poisson_reg = sm.Poisson(df[['numbil0']], df[reg1],\n",
    "                         missing='drop').fit(cov_type='HC0', maxiter=100)\n",
    "print(poisson_reg.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```none\n",
    "Optimization terminated successfully.\n",
    "         Current function value: 2.226090\n",
    "         Iterations 36\n",
    "                          Poisson Regression Results\n",
    "==============================================================================\n",
    "Dep. Variable:                numbil0   No. Observations:                  197\n",
    "Model:                        Poisson   Df Residuals:                      193\n",
    "Method:                           MLE   Df Model:                            3\n",
    "Date:                Wed, 26 Jul 2017   Pseudo R-squ.:                  0.8574\n",
    "Time:                        15:41:38   Log-Likelihood:                -438.54\n",
    "converged:                       True   LL-Null:                       -3074.7\n",
    "                                        LLR p-value:                     0.000\n",
    "==============================================================================\n",
    "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
    "------------------------------------------------------------------------------\n",
    "const        -29.0495      2.578    -11.268      0.000     -34.103     -23.997\n",
    "lngdppc        1.0839      0.138      7.834      0.000       0.813       1.355\n",
    "lnpop          1.1714      0.097     12.024      0.000       0.980       1.362\n",
    "gattwto08      0.0060      0.007      0.868      0.386      -0.008       0.019\n",
    "==============================================================================\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.iolib.summary2 import summary_col\n",
    "\n",
    "regs = [reg1, reg2, reg3]\n",
    "reg_names = ['Model 1', 'Model 2', 'Model 3']\n",
    "info_dict = {'Pseudo R-squared': lambda x: \"{:.2f}\".format(x.prsquared),\n",
    "             'No. observations': lambda x: \"{0:d}\".format(int(x.nobs))}\n",
    "regressor_order = ['const',\n",
    "                   'lngdppc',\n",
    "                   'lnpop',\n",
    "                   'gattwto08',\n",
    "                   'lnmcap08',\n",
    "                   'rintr',\n",
    "                   'topint08',\n",
    "                   'nrrents',\n",
    "                   'roflaw']\n",
    "results = []\n",
    "\n",
    "for reg in regs:\n",
    "    result = sm.Poisson(df[['numbil0']], df[reg],\n",
    "                        missing='drop').fit(cov_type='HC0', maxiter=100, disp=0)\n",
    "    results.append(result)\n",
    "\n",
    "results_table = summary_col(results=results,\n",
    "                            float_format='%0.3f',\n",
    "                            stars=True,\n",
    "                            model_names=reg_names,\n",
    "                            info_dict=info_dict,\n",
    "                            regressor_order=regressor_order)\n",
    "results_table.add_title('Table 1 - Explaining the Number of Billionaires in 2008')\n",
    "print(results_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```none\n",
    "Table 1 - Explaining the Number of Billionaires in 2008\n",
    "=================================================\n",
    "                  Model 1    Model 2    Model 3\n",
    "-------------------------------------------------\n",
    "const            -29.050*** -19.444*** -20.858***\n",
    "                 (2.578)    (4.820)    (4.255)\n",
    "lngdppc          1.084***   0.717***   0.737***\n",
    "                 (0.138)    (0.244)    (0.233)\n",
    "lnpop            1.171***   0.806***   0.929***\n",
    "                 (0.097)    (0.213)    (0.195)\n",
    "gattwto08        0.006      0.007      0.004\n",
    "                 (0.007)    (0.006)    (0.006)\n",
    "lnmcap08                    0.399**    0.286*\n",
    "                            (0.172)    (0.167)\n",
    "rintr                       -0.010     -0.009\n",
    "                            (0.010)    (0.010)\n",
    "topint08                    -0.051***  -0.058***\n",
    "                            (0.011)    (0.012)\n",
    "nrrents                                -0.005\n",
    "                                       (0.010)\n",
    "roflaw                                 0.203\n",
    "                                       (0.372)\n",
    "Pseudo R-squared 0.86       0.90       0.90\n",
    "No. observations 197        131        131\n",
    "=================================================\n",
    "Standard errors in parentheses.\n",
    "* p<.1, ** p<.05, ***p<.01\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ['const', 'lngdppc', 'lnpop', 'gattwto08', 'lnmcap08', 'rintr',\n",
    "        'topint08', 'nrrents', 'roflaw', 'numbil0', 'country']\n",
    "results_df = df[data].dropna()\n",
    "\n",
    "# Use last model (model 3)\n",
    "results_df['prediction'] = results[-1].predict()\n",
    "\n",
    "# Calculate difference\n",
    "results_df['difference'] = results_df['numbil0'] - results_df['prediction']\n",
    "\n",
    "# Sort in descending order\n",
    "results_df.sort_values('difference', ascending=False, inplace=True)\n",
    "\n",
    "# Plot the first 15 data points\n",
    "results_df[:15].plot('country', 'difference', kind='bar', figsize=(12,8), legend=False)\n",
    "plt.ylabel('Number of billionaires above predicted level')\n",
    "plt.xlabel('Country')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.discrete.discrete_model import Probit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "class ProbitRegression:\n",
    "\n",
    "    def __init__(self, y, X, beta):\n",
    "        self.X, self.y, self.beta = X, y, beta\n",
    "        self.n, self.k = X.shape\n",
    "\n",
    "    def mu(self):\n",
    "        return norm.cdf(np.dot(self.X, self.beta.T))\n",
    "\n",
    "    def phi(self):\n",
    "        return norm.pdf(np.dot(self.X, self.beta.T))\n",
    "\n",
    "    def logL(self):\n",
    "        mu = self.mu()\n",
    "        return np.sum(y * np.log(mu) + (1-y) * np.log(1-mu))\n",
    "\n",
    "    def G(self):\n",
    "        mu = self.mu()\n",
    "        phi = self.phi()\n",
    "        return np.sum((X.T * y*phi/mu - X.T * (1-y)*phi/(1-mu)), axis=1)\n",
    "\n",
    "    def H(self):\n",
    "        X = self.X\n",
    "        beta = self.beta\n",
    "        mu = self.mu()\n",
    "        phi = self.phi()\n",
    "        a = (phi + np.dot(X, beta.T) * mu) / mu**2\n",
    "        b = (phi - np.dot(X, beta.T) * (1 - mu)) / (1-mu)**2\n",
    "        return -np.dot(phi * (y*a + (1-y)*b) * X.T, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[1, 2, 4],\n",
    "              [1, 1, 1],\n",
    "              [1, 4, 3],\n",
    "              [1, 5, 6],\n",
    "              [1, 3, 5]])\n",
    "\n",
    "y = np.array([1, 0, 1, 1, 0])\n",
    "\n",
    "# Take a guess at initial betas\n",
    "beta = np.array([0.1, 0.1, 0.1])\n",
    "\n",
    "# Create instance of Probit regression class\n",
    "prob = ProbitRegression(y, X, beta)\n",
    "\n",
    "# Run Newton-Raphson algorithm\n",
    "newton_raphson(prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```none\n",
    "Iteration_k  Log-likelihood  Theta\n",
    "-----------------------------------------------------------\n",
    "0            -2.37968841     ['-1.3400', '0.7750', '-0.1570']\n",
    "1            -2.36875259     ['-1.5350', '0.7750', '-0.0980']\n",
    "2            -2.36872942     ['-1.5460', '0.7780', '-0.0970']\n",
    "3            -2.36872942     ['-1.5460', '0.7780', '-0.0970']\n",
    "Number of iterations: 4\n",
    "beta_hat = [-1.54625858  0.77778952 -0.09709757]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```none\n",
    "array([-1.54625858,  0.77778952, -0.09709757])\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use statsmodels to verify results\n",
    "\n",
    "print(Probit(y, X).fit().summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```none\n",
    "Optimization terminated successfully.\n",
    "         Current function value: 0.473746\n",
    "         Iterations 6\n",
    "                          Probit Regression Results\n",
    "==============================================================================\n",
    "Dep. Variable:                      y   No. Observations:                    5\n",
    "Model:                         Probit   Df Residuals:                        2\n",
    "Method:                           MLE   Df Model:                            2\n",
    "Date:                Wed, 26 Jul 2017   Pseudo R-squ.:                  0.2961\n",
    "Time:                        15:41:39   Log-Likelihood:                -2.3687\n",
    "converged:                       True   LL-Null:                       -3.3651\n",
    "                                        LLR p-value:                    0.3692\n",
    "==============================================================================\n",
    "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
    "------------------------------------------------------------------------------\n",
    "const         -1.5463      1.866     -0.829      0.407      -5.204       2.111\n",
    "x1             0.7778      0.788      0.986      0.324      -0.768       2.323\n",
    "x2            -0.0971      0.590     -0.165      0.869      -1.254       1.060\n",
    "==============================================================================\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}